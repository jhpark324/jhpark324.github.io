---
layout: single
title: "[LangGraph] 문서 파싱 -> Langgraph 구현
categories: LangGraph
tags: [LangGraph]
toc: true

---

## langgraph를 이용한 졸업 요건 계산

### 성적표 파싱

#### PyPDFLoader

```python
pdf_file_path = "./data/grade_report.pdf"
loader = PyPDFLoader(pdf_file_path)
pages = []
async for page in loader.alazy_load():
    pages.append(page)
```

- pyPDFLoader를 활용했을때 표같은 레이아웃에 약함
- 대안) pyzerox를 활용

#### pyzerox

```python
kwargs = {}

custom_system_prompt = None

model = 'gpt-5'
async def main():
    file_path = "./data/grade_report.pdf"
    select_pages = None
    output_dir = "./data"
    result = await zerox(file_path=file_path, model=model, output_dir=output_dir,
                        custom_system_prompt=custom_system_prompt,
                        select_pages=select_pages)
 
    return result

result_gpt_5 = asyncio.run(main())

```

```python
with open("./data/grade_report_gpt-5.md", "rb") as f:
    check_result = chardet.detect(f.read())
print(check_result)
```

- 파일 인코딩 체크

```python
src = "./data/grade_report_gpt-5.md"
dst = "./data/grade_report_gpt-5_utf8.md"

with open(src, "r", encoding="euc-kr", errors="ignore") as f:
    text = f.read()

with open(dst, "w", encoding="utf-8") as f:
    f.write(text)

print(" EUC-KR - UTF-8 변환 완료:", dst)
```

- utf-8 버전으로 변환

```python
import markdown
from bs4 import BeautifulSoup

text_path = './data/grade_report_gpt-5.txt'

with open(markdown_path, 'r', encoding='utf-8') as md_file:
    md_content = md_file.read()

html_content = markdown.markdown(md_content)

soup = BeautifulSoup(html_content, 'html.parser')
text_content = soup.get_text()

with open(text_path, 'w', encoding = 'utf-8') as txt_file:
    txt_file.write(text_content)

print("Markdown coverted to plain text successfully")  
```

- 위의 과정들을 통해 처리한 파싱 과정
- pdf -> md: 레이아웃을 살리기 위함
- md -> html -> txt: llm에 넣기 쉽게 하기 위함

---

### 졸업요건관련 세칙 파일

- 위의 과정과 동일하게 파싱

``` python
embeddings = OpenAIEmbeddings(model='text-embedding-3-large')
vector_store = Chroma.from_documents(
    documents=documents_list ,
    embedding=embeddings,
    collection_name='grad_collection',
    persist_directory='./grad_collection'

)
```

- 졸업요건관련 세칙 파일로 벡터DB생성
  - 임베딩된 벡터 DB란? : 단어간의 유사도 기반

```python
retriever = vector_store.as_retriever(search_kwargs={'k': 2})
query = '나는 24학번 화학공학과인데 졸업요건은 지금 어때'
retriever.invoke(query)
```

- 해당 쿼리랑 가장 유사한 문서 두개 가져옴
  - 모델마다 성능이 다르므로 테스트 해야함

---

### langgraph 구성

```python
class AgentState(TypedDict):
    query:str
    context: List[Document]
    answer: str
```

- 에이전트가 가지고 있을 상태 클래스 정의
- 쿼리, 컨텍스트, 답변

```python
def load_grade_txt_as_docs(path: str) -> List[Document]:
    docs: List[Document] = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            docs.append(Document(page_content=line))
    return docs
grade_docs = load_grade_txt_as_docs("data/grade_report_gpt-5.txt")
```

- 문서를 줄마다 페이지화
- 나중에 결과랑 비교해서 필요하지 않은 정보는 지워서 토큰을 줄일 수 있음

```python
def retrieve(state: AgentState) -> AgentState:
    query = state['query']
    docs = retriever.invoke(query)
    return{'context': docs}
```

- 문서를 검색하는 retrieve 노드 만듬

```python
prompt = PromptTemplate.from_template("""
당신은 대학 행정 도우미입니다.
아래의 [context]와 [grade_report]를 참조해서 [query]에 답변해주세요.
답변은 남은학기동안 전공과 교양을 얼마나 더 들어야하는지 위주로 답변해주세요.
[query]: {query}
[context]: {context}
[grade_report]: {grade_report}                                    

""")
llm = ChatGoogleGenerativeAI(model='gpt-5')
```

- prompt와 llm정의 

```python
def generate(state: AgentState) -> AgentState:
    context = state['context']
    query = state['query']
    rag_chain = prompt | llm
    response = rag_chain.invoke({'query': query, 'context': context, 'grade_report': grade_docs})
    return {'answer': response}
```

- 최종 답변을 하는 generate노드 정의
- chain만들어서 프롬포트를 llm 즉 모델에 전달

```python
graph_builder = StateGraph(AgentState)
graph_builder.add_node('retrieve', retrieve)
graph_builder.add_node('generate', generate)
graph_builder.add_edge(START, 'retrieve')
graph_builder.add_edge('retrieve', 'generate')
graph_builder.add_edge('generate', END)
graph = graph_builder.compile()
display(Image(graph.get_graph().draw_mermaid_png()))
```

- 각 노드와 엣지를 연결하고 컴파일
- 시각화

```python
initial_state = {'query': query}
result = graph.invoke(initial_state)
result["answer"]
```

- 쿼리를 invoke하고 실행한 뒤 답변만 출력

```mark
AIMessage(content='요약(24학번 화학공학과, 현재 성적표 기준)\n- 총 취득학점: 87/120 → 33학점 남음\n- 전공 이수: 전핵+전선 합계 약 37학점 이수\n- 교양 이수: 교필+교선 합계 약 29학점 이수\n\n남은 학점(학과/학번별 요건 가정 포함)\n- 교양: 공통 안내(2025학번 기준)로 교양 37학점이면 → 약 8학점 더 필요\n- 전공: 학과 편람의 전공 최소이수학점(전핵+전선) 충족 필요. 현재 37학점이므로\n  - 전공 최소 48학점 기준일 경우 → 전공 11학점 추가\n  - 전공 최소 60학점 기준일 경우 → 전공 23학점 추가\n- 나머지는 일반선택으로 채우면 총 120학점 충족\n\n주의\n- 24학번 화공과 전공 최소이수학점·필수과목(전공필수/기초교양 지정과목) 표를 확인해야 정확히 확정됩니다.\n- 학과 편람(2024학년도 화학공학과) 기준 전공 최소학점과 교양 요건 알려주시면, 전공/교양 정확 잔여학점으로 다시 계산해드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4238, 'prompt_tokens': 3453, 'total_tokens': 7691, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 3904, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CbOjZJn8NDvOZTBoXdTQfyze71I6g', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0f1cb5b0-6d42-4ed7-afb2-b4bc567370ed-0', usage_metadata={'input_tokens': 3453, 'output_tokens': 4238, 'total_tokens': 7691, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 3904}})
```

- 24학번 기준이 안잡히는 걸 확인 할 수 있음
-  임베딩 모델 수정 고려
- 문서 추가 고려

| 공부용으로 주피터노트북을 사용하였고 이를 블로그로 옮기는 과정에서 필요한 내용만 간단히 담았습니다.
